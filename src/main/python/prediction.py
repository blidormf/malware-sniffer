import numpy as np
from keras.models import load_model
from keras.layers import Layer
import keras.backend as K
import tensorflow as tf
from keras.initializers import RandomNormal
from tensorflow.keras.layers import InputSpec
from keras.models import Model, Sequential
from keras.layers import Dense, Dropout, Input, Lambda, Conv1D, MaxPooling1D, Flatten, UpSampling1D
from keras.layers import Reshape, Multiply, Add, Conv2D, MaxPooling2D, UpSampling2D
import keras.regularizers as regularizers
import keras.initializers as initializers
from keras.regularizers import l2, Regularizer
from tensorflow.keras.optimizers import SGD
from sklearn.preprocessing import normalize

import src.malware_smell.keras_smell


class MarkerLayer(Layer):
    def __init__(self, output_dim=2, input_dim=None, pos_markers=3, markers=5, alpha=1.0, kernel_regularizer=None,
                 distance=8, **kwargs):
        self.output_dim = output_dim
        self.input_dim = input_dim
        self.alpha = alpha
        self.encoding_dim = 6
        self.distance = distance
        self.input_spec = [InputSpec(ndim=2)]
        self.kernel_regularizer = regularizers.get(kernel_regularizer)
        self.pos_markers = pos_markers
        self.markers = markers

        if self.input_dim:
            kwargs['input_shape'] = (self.input_dim,)
        super(MarkerLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        assert len(input_shape) == 2
        input_dim = input_shape[1]
        self.input_spec = [InputSpec(dtype=K.floatx(), shape=(None, input_dim))]
        self.W = self.add_weight(shape=(self.markers, input_dim),
                                 initializer='glorot_uniform',
                                 trainable=True)
        super(MarkerLayer, self).build(input_shape)

    def call(self, x, mask=None):
        num_pos = self.pos_markers
        q = 1.0 / (1.0 + K.sqrt(K.sum(K.square(K.expand_dims(x, 1) - self.W), axis=2)) ** 2 / self.alpha)
        q = q ** ((self.alpha + 1.0) / 2.0)
        q = K.transpose(K.transpose(q) / K.sum(q, axis=1))
        pos = K.sum(q[:, :num_pos], axis=1)
        neg = K.sum(q[:, num_pos:], axis=1)
        q_new = K.concatenate([pos, neg])
        q_new = K.transpose(K.reshape(q_new, [2, -1]))
        return q_new

    def get_output_shape_for(self, input_shape):
        assert input_shape and len(input_shape) == 2
        return (input_shape[0], self.output_dim)

    def compute_output_shape(self, input_shape):
        assert input_shape and len(input_shape) == 2
        return (input_shape[0], self.output_dim)

    def get_config(self):
        config = {
            'output_dim': self.output_dim,
            'input_dim': self.input_dim,
            'pos_markers': self.pos_markers,
            'markers': self.markers,
            'alpha': self.alpha,
            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),
            'distance': self.distance
        }
        base_config = super(MarkerLayer, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


def preprocess_file(file_path):
    # Read the binary file
    with open(file_path, 'rb') as file:
        binary_data = file.read()

    # Convert binary data to 8-bit unsigned integers
    binary_vector = np.frombuffer(binary_data, dtype=np.uint8)

    # Pad or truncate the vector to a fixed size (e.g., 64 * 64)
    fixed_size = 64 * 64
    if len(binary_vector) < fixed_size:
        binary_vector = np.pad(binary_vector, (0, fixed_size - len(binary_vector)), 'constant')
    else:
        binary_vector = binary_vector[:fixed_size]

    # Reshape the vector into a 2D matrix (e.g., 64x64)
    binary_matrix = binary_vector.reshape((64, 64))

    # Normalize the matrix values to the range [0, 1]
    normalized_matrix = binary_matrix / 255.0

    # Reshape the matrix into the input shape expected by the model (e.g., (1, 64, 64, 1))
    input_data = normalized_matrix.reshape((1, 64, 64, 1))

    return input_data


def predict_malware(file_path, preprocessed_reference_files, model, threshold=0.5):
    # Preprocess the input file
    input_data = preprocess_file(file_path)

    # Initialize variables to store the sum of dissimilarity scores and the count of reference files
    dissimilarity_sum = 0
    count = 0

    # Iterate over each preprocessed reference file
    for preprocessed_file in preprocessed_reference_files:
        # Load the preprocessed reference data
        reference_data = np.load(preprocessed_file)

        # Reshape the reference data to have a single sample
        reference_data = reference_data.reshape((1, 64, 64, 1))

        # Make predictions using the loaded model
        predictions = model.predict([input_data, reference_data], verbose=0)

        # Get the dissimilarity score (probability of being different from the malicious reference file)
        dissimilarity_score = predictions[0][1]

        # Add the dissimilarity score to the sum
        dissimilarity_sum += dissimilarity_score

        # Increment the count of reference files
        count += 1

    # Calculate the average dissimilarity score across all reference files
    avg_dissimilarity_score = dissimilarity_sum / count

    # Convert the average dissimilarity score to the probability of being malicious
    malware_probability = 1 - avg_dissimilarity_score

    # Determine if the file is malicious based on the threshold
    is_malicious = malware_probability >= threshold

    return is_malicious


# Load the saved Malware-SMELL model
model_path = 'src/main/python/src/malware_smell/smell_model.h5'
loaded_model = load_model(model_path, custom_objects={'MarkerLayer': MarkerLayer})

# Specify the path to the reference file (a known benign file)
reference_files = []

for i in range(0, 100):
    reference_files.append('src/main/python/db/X[' + str(i) + '].npy')

# Set the threshold for determining if a file is malicious
malware_threshold = 0.5

import sys

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("Please provide a file path as a command-line argument.")
    else:
        file_path = sys.argv[1]
        is_malicious = predict_malware(file_path, reference_files, loaded_model, threshold=malware_threshold)

        if is_malicious:
            print("malicious")
        else:
            print("benign")

